import streamlit as st
import google.generativeai as genai

# Sayfa Ayarlar覺
st.set_page_config(page_title="FLL Kural Asistan覺", page_icon="")
st.title(" FLL Submerged - Kural Asistan覺")

# 1. API KEY KONTROL
try:
    api_key = st.secrets["GOOGLE_API_KEY"]
    genai.configure(api_key=api_key)
except Exception as e:
    st.error("API Key hatas覺! L羹tfen Streamlit Secrets ayarlar覺n覺 kontrol edin.")
    st.error(f"Hata detay覺: {e}")
    st.stop()

# 2. MODEL AYARLARI (En kararl覺 s羹r羹m羹 kullan覺yoruz)
SYSTEM_PROMPT = """
Sen uzman bir FLL Bahakemisin. 
Sorular覺 yan覺tlarken FLL Robot Oyunu kural kitap癟覺覺n覺 referans al.
Daima nazik ve 繹retici ol. Cevaplar覺nda kural maddelerini (R12, M04 gibi) belirt.
"""

# Modeli olutur
model = genai.GenerativeModel(
    model_name="gemini-1.5-flash", # "latest" yerine bunu kullan覺yoruz
    system_instruction=SYSTEM_PROMPT
)

# 3. SOHBET GEM襤襤 BALATMA
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mesajlar覺 ekrana yazd覺r
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# 4. KULLANICI G襤R襤襤 VE CEVAP
if prompt := st.chat_input("Sorunuzu buraya yaz覺n..."):
    # Kullan覺c覺 mesaj覺n覺 ekle
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Bot cevab覺n覺 羹ret
    with st.chat_message("assistant"):
        try:
            # Sohbet ge癟miini Gemini format覺na 癟evir
            # Hata 癟覺kmamas覺 i癟in ge癟mii temizleyip sadece son soruyu da g繹nderebiliriz
            # Ama balam覺 korumak i癟in unu deniyoruz:
            history_for_gemini = []
            for m in st.session_state.messages[:-1]:
                role = "user" if m["role"] == "user" else "model"
                history_for_gemini.append({"role": role, "parts": [m["content"]]})

            chat = model.start_chat(history=history_for_gemini)
            
            # Cevab覺 al (stream=False yapt覺k hata ay覺klamak daha kolay olsun diye)
            response = chat.send_message(prompt)
            st.markdown(response.text)
            
            # Ge癟mie ekle
            st.session_state.messages.append({"role": "model", "content": response.text})
            
        except Exception as e:
            # HATAYI BURADA YAKALAYIP EKRANA BASIYORUZ
            st.error("Bir hata olutu:")
            st.code(e)
            # Hata durumunda ge癟mii temizlemek bazen kurtar覺c覺 olur
            if st.button("Sohbeti S覺f覺rla"):
                st.session_state.messages = []
                st.rerun()
